{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`aye` creates tools to load "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    __doc__ = \"\"\"\n",
    "    This notebook creates a module named `aye`.  `aye` \n",
    "    allows users to import notebooks as Python modules with _sorta_ improved debugging features.\n",
    "    \n",
    "    # Suppressing expressions when importing notebooks\n",
    "    \n",
    "    Use the condition \n",
    "    \n",
    "        __name__ == '__main__'\n",
    "    \n",
    "    as a control flow to ignore stay\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Updating `sys.path_hooks`\n",
    "\n",
    "[Registering path hooks][302], [Import Hooks][imp]\n",
    "\n",
    "[302]: https://www.python.org/dev/peps/pep-0302/#id28\n",
    "[imp]: https://docs.python.org/3/reference/import.html#import-hooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    def update_hooks(*loaders):\n",
    "        \"\"\"Append custom loaders to the `sys.path_hooks`, they must \n",
    "        have a tuple attribute EXTENSION_SUFFIXES to discover the correct path.\n",
    "        \n",
    "        _NATIVE_HOOK resides in the global scope to reset the original sys.path_hooks \n",
    "        if necessary..\n",
    "        \"\"\"\n",
    "        global _NATIVE_HOOK\n",
    "        from importlib.machinery import FileFinder\n",
    "        \n",
    "        if loaders:\n",
    "            for i, hook in enumerate(sys.path_hooks):\n",
    "                __closure__ = getattr(hook, '__closure__', None)\n",
    "                if __closure__ and issubclass(__closure__[0].cell_contents, FileFinder):\n",
    "                    _NATIVE_HOOK = globals().get('_NATIVE_HOOK', (i, hook))\n",
    "                    sys.path_hooks[i] = FileFinder.path_hook(\n",
    "                        *_NATIVE_HOOK[1].__closure__[1].cell_contents,\n",
    "                        *((loader, loader.EXTENSION_SUFFIXES) for loader in loaders\n",
    "                    ))\n",
    "        else:\n",
    "            sys.path_hooks[_NATIVE_HOOK[0]] = _NATIVE_HOOK[1]\n",
    "                \n",
    "        \"\"\"https://docs.python.org/3/library/sys.html#sys.path_importer_cache\"\"\"\n",
    "        sys.path_importer_cache.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sys.path_importer_cache.clear()`\n",
    "\n",
    "\n",
    "[jup]: http://jupyter-notebook.readthedocs.io/en/stable/examples/Notebook/Importing%20Notebooks.html#Register-the-hook\n",
    "[importable]: https://github.com/tonyfast/importable/blob/master/importable.py#L83"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    from IPython.utils.capture import capture_output\n",
    "    from IPython.display import publish_display_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "    from contextlib import contextmanager\n",
    "    @contextmanager\n",
    "    def Import(*loaders, capture=False): \n",
    "        \"\"\"A contextmanager that modifies the sys.path_hooks and returns them \n",
    "        to their original state.\n",
    "        \n",
    "        \"\"\"\n",
    "        if capture:\n",
    "            with capture_output() as captured:\n",
    "                update_hooks(*loaders or [Notebook])\n",
    "                yield captured\n",
    "                update_hooks()\n",
    "        else:\n",
    "            yield update_hooks(*loaders or [Notebook]); update_hooks()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loaders \n",
    "\n",
    "[Import loaders][load]\n",
    "\n",
    "[load]: https://docs.python.org/3/reference/import.html#loaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook Source File Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    from importlib.machinery import SourceFileLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The native [`importlib.machinery.SourceFileLoader`](https://docs.python.org/3/library/importlib.html#importlib.machinery.SourceFileLoader) provides the general API to import modules from files.  This API will compile and cache the byte-code like a normal module in __pycache__.\n",
    "\n",
    "> The [UML diagram of `eye`](#uml-diagram) illustrates all of the methods provided by the loader.\n",
    "\n",
    "`Notebook` uses the [`SourceFileLoader.source_to_code`](https://docs.python.org/3/library/importlib.html#importlib.abc.InspectLoader.source_to_code)\n",
    "method to transform the source string into valid python AST.  `Notebook.source_to_code` calls a new method `Notebook.source_to_lines`\n",
    "that decodes the string into blocks of iterable source code; `Notebook.source_to_lines` can be used by other \n",
    "methods to customize `Module` imports.\n",
    "\n",
    "It is necessary that the `Notebook` __loader__ can `importlib.reload` the modules it produces.\n",
    "\n",
    "## Completeness\n",
    "\n",
    "`Notebook.exec_module` catches all errors on the attribute __complete__.  With this approach all notebooks with important and the user can \n",
    "\n",
    "    raise nb.__complete__ \n",
    "    \n",
    "to return a __traceback__.  A successful import will `assert nb.__complete__`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    class Partial(SourceFileLoader):\n",
    "        \"\"\"A SourceFileLoader specifically designed for `nbformat.v4` files. The `Notebook`\n",
    "        loader will create compiled python byte code for better interactive debugging.\n",
    "        \n",
    "        \"\"\"\n",
    "        def source_to_code(Notebook, data, path, *, _optimize=-1):\n",
    "            \"\"\"Introduces `source_to_lines` to the standard import pipeline.\n",
    "            \"\"\"\n",
    "            return super().source_to_code(lines_to_ast(\n",
    "                Notebook.source_to_lines(Notebook.get_source(Notebook.name))\n",
    "            ), path, _optimize=_optimize)\n",
    "\n",
    "        @staticmethod\n",
    "        def source_to_lines(data:str)->'Iterator[Tuple(Int, Str)]':\n",
    "            \"\"\"Transform `NotebookNode.cells`, with `nbformat.v4`, into source code objects\n",
    "            with the corresponding lines number in source `.ipynb` files.  The `new_decoder` is \n",
    "            a `json.decoder` that extracts the line numbers and code blocks from the source file.\n",
    "            \"\"\"\n",
    "            yield 1, data\n",
    "        \n",
    "        def exec_module(Notebook, module):\n",
    "            \"\"\"exec_module explicitly rewrites _bootstrap_external._LoaderBasics.exec_module\n",
    "            to pass globals into the import.  \n",
    "            \n",
    "            This version of exec_module will always __complete__ if an ImportError is not raised.\n",
    "            __complete__ may hold an exception.\n",
    "            \"\"\"\n",
    "            from importlib import _bootstrap_external, _bootstrap\n",
    "            from types import MethodType\n",
    "            \n",
    "            module.__doc__ = module.__doc__ or \"\"\"\"\"\"\n",
    "            module.__complete__ = False\n",
    "            code = Notebook.get_code(module.__name__)\n",
    "            code is None and \"\"\"Raise the expected error.\"\"\" and super().exec_module(module)\n",
    "            try: \n",
    "                _bootstrap._call_with_frames_removed(exec, code, module.__dict__, module.__dict__)\n",
    "                module.__complete__ = True\n",
    "            except BaseException as Exception: module.__complete__ = Exception\n",
    "            return module #repr_markdown(module)\n",
    "        \n",
    "        __complete__ = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    class Notebook(Partial):\n",
    "        \"\"\"A SourceFileLoader specifically designed for `nbformat.v4` files. The `Notebook`\n",
    "        loader will create compiled python byte code for better interactive debugging.\n",
    "        \n",
    "        \"\"\"\n",
    "        EXTENSION_SUFFIXES = '.ipynb',\n",
    "        \n",
    "        @staticmethod\n",
    "        def source_to_lines(data:str)->'Iterator[Tuple(Int, Str)]':\n",
    "            \"\"\"Transform `NotebookNode.cells`, with `nbformat.v4`, into source code objects\n",
    "            with the corresponding lines number in source `.ipynb` files.  The `new_decoder` is \n",
    "            a `json.decoder` that extracts the line numbers and code blocks from the source file.\n",
    "            \"\"\"\n",
    "            yield from new_decoder().decode(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoding `nbformat.v4`\n",
    "\n",
    "`NBDecoder` is a custom [`JSONDecoder.parse_object`](https://docs.python.org/3/library/json.html#json.JSONDecoder) that applies special operations on the `NotebookNode.source` and\n",
    "`NotebookNode.cells`.  The line numbers must be recorded in the decoder.\n",
    "\n",
    "> `nbformat` is not formally called, it is assumed the data structure is valid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    from json.decoder import WHITESPACE, WHITESPACE_STR\n",
    "    def NBDecoder(s_and_end, strict, scan_once, object_hook, \n",
    "                  object_pairs_hook, memo=None, _w=WHITESPACE.match, _ws=WHITESPACE_STR):\n",
    "        from json.decoder import JSONObject\n",
    "        from nbconvert.filters import comment_lines, indent\n",
    "        \n",
    "        doc, id = s_and_end\n",
    "\n",
    "        object, next = JSONObject((doc, id), strict, scan_once, object_hook, object_pairs_hook, memo=memo, _w=_w, _ws=_ws)\n",
    "        if 'source' in object:\n",
    "            type, object = object['cell_type'], object['source']\n",
    "            object = ''.join(object) if isinstance(object, list) else object            \n",
    "            id = doc.count('\\n', 0, id + doc[id:next].find(object and object.splitlines()[0] or 'source'))\n",
    "            object = id, (object if type == 'code' else comment_lines(object))\n",
    "        elif 'cells' in object:\n",
    "            object = object['cells']\n",
    "\n",
    "        return object, next\n",
    "\n",
    "    def new_decoder():\n",
    "        from json.decoder import JSONDecoder\n",
    "        from json.scanner import py_make_scanner\n",
    "        decoder = JSONDecoder()\n",
    "        decoder.parse_object = NBDecoder\n",
    "        decoder.scan_once = py_make_scanner(decoder)\n",
    "        return decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Literate Markdown Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    from nbconvert.filters.markdown_mistune import IPythonRenderer, MarkdownWithMath\n",
    "    class Markdown(MarkdownWithMath):\n",
    "        \"\"\"A mistune.Markdown object that accumulates the source code in the markdown body.\n",
    "        \"\"\"\n",
    "        def render(Markdown, text):\n",
    "            from nbconvert.filters import ipython2python\n",
    "            Markdown.renderer.source = \"\"\"\"\"\"\n",
    "            return [super().render(text), ipython2python(Markdown.renderer.source)][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    class Renderer(IPythonRenderer):\n",
    "        \"\"\"A mistune.Renderer to use with `aye.Markdown`.\"\"\"\n",
    "        def __init__(Renderer, *args, **kwargs): \n",
    "            Renderer.source = super().__init__(*args, **kwargs) or \"\"\"\"\"\"\n",
    "\n",
    "        def block_code(Renderer, str, lang=None):\n",
    "            Renderer.source += '\\n' + str\n",
    "            return super().block_code(str, lang=lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    class Literate(Notebook):\n",
    "        \"\"\"A loader for literate Markdown notebooks.\"\"\"\n",
    "        def source_to_lines(Notebook, data, body=\"\"\"\"\"\"): \n",
    "            md = Markdown(Renderer())\n",
    "            for id, str in super().source_to_lines(data): \n",
    "                yield id, (md.render(str), md.renderer.source)[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    class MD(Partial):\n",
    "        EXTENSION_SUFFIXES = '.md', '.markdown'\n",
    "        def source_to_lines(Notebook, data, body=\"\"\"\"\"\"): \n",
    "            from textwrap import dedent\n",
    "            from nbconvert.filters import ipython2python\n",
    "            md = Markdown(Renderer())\n",
    "            md.render(data)\n",
    "            yield 1, ipython2python(dedent(md.renderer.source))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IPython tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    import sys\n",
    "    from importlib import reload\n",
    "\n",
    "    def ast(Notebook): \n",
    "        loader = Notebook.__loader__\n",
    "        return lines_to_ast(loader.source_to_lines(loader.get_source(loader.name)))\n",
    "    \n",
    "    def free_expressions(module):\n",
    "        from collections import OrderedDict\n",
    "        from ast import Expr, Str, Assign, Module, parse, literal_eval, dump\n",
    "        dict, assigned = OrderedDict(), list()\n",
    "        new = Module(body=[])\n",
    "        for node in module.body:\n",
    "            if isinstance(node, Expr) and isinstance(node.value, Str):\n",
    "                params = parse(node.value.s).body\n",
    "                if params and isinstance(params[0], Assign) and len(params[0].targets) is 1: \n",
    "                    dict[params[0].targets[0].id] = literal_eval(params[0].value)\n",
    "                    assigned.append(dump(params[0].targets[0]))\n",
    "            elif isinstance(node, Assign) and node.targets and dump(node.targets[0]) in assigned:\n",
    "                \"\"\"Do not append parameterized assigments.\"\"\"\n",
    "            else: new.body.append(node)\n",
    "        return dict, new\n",
    "\n",
    "    def vars_to_sig(vars):\n",
    "        from inspect import Parameter, Signature\n",
    "        return Signature([Parameter(str, Parameter.KEYWORD_ONLY, default = vars[str]) for str in vars])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def copy_module(module):\n",
    "        from types import ModuleType\n",
    "        new = ModuleType(module.__name__, module.__doc__)\n",
    "        new.__dict__.update(module.__dict__)\n",
    "        return new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    def parameterize(nb):\n",
    "        module = copy_module(nb)\n",
    "        AST = ast(module)\n",
    "        variables, AST = free_expressions(AST)\n",
    "        for variable in variables: \n",
    "            if variable in module.__dict__: module.__dict__.pop(variable)\n",
    "        \n",
    "        module.__dict__.update(variables)\n",
    "        \n",
    "        def run(**kwargs): \n",
    "            module.__dict__.update(kwargs)\n",
    "            exec(\n",
    "                compile(AST, module.__file__, 'exec'), \n",
    "                module.__dict__, module.__dict__)\n",
    "            return module\n",
    "        run._variables = variables\n",
    "        run.__signature__ = vars_to_sig(variables)\n",
    "        run.__doc__ = nb.__doc__\n",
    "        return run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    def lines_to_ast(lines):\n",
    "        \"\"\"Transform `lines` of Python source to Python AST with the correct\n",
    "        lines numbers to the original notebook source.\n",
    "        \"\"\"\n",
    "        from ast import Module, parse, increment_lineno\n",
    "        from nbconvert.filters import ipython2python\n",
    "        module = Module(body=[])\n",
    "        for id, str in lines: module.body.extend(\n",
    "            increment_lineno(node, id) for node in parse(ipython2python(str)).body)\n",
    "        return module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    def from_file(path, loader=Notebook, capture=False):\n",
    "        \"\"\"from_file loads paths as modules with a specified loader.\n",
    "        \n",
    "        >>> m = from_file('aye.ipynb')\n",
    "        >>> mods = set(dir(__import__('sys').modules))\n",
    "        >>> assert m.__complete__ is True\n",
    "        >>> assert m.__name__\n",
    "        >>> assert len(set(dir(__import__('sys').modules)) - mods) is 0\n",
    "        \"\"\"\n",
    "        from importlib._bootstrap import _init_module_attrs\n",
    "        from importlib.util import spec_from_file_location, module_from_spec\n",
    "        from types import ModuleType\n",
    "        # module = module_from_spec()\n",
    "        # Create the module by hand to avoid the package name winding up in the sys.modules.\n",
    "        module = _init_module_attrs(\n",
    "            spec_from_file_location(path, path, loader=loader(path, path)), ModuleType(path, \"\"\"\"\"\"))\n",
    "        \n",
    "        if capture:\n",
    "            with capture_output() as captured:\n",
    "                module.__loader__.exec_module(module)\n",
    "            module.__output__ = captured\n",
    "        else:\n",
    "            module.__loader__.exec_module(module)\n",
    "        return module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    def repr_markdown(module):\n",
    "        \"\"\"Attach a [Markdown Formatter][format] to modules loaded by `aye`.\n",
    "        \n",
    "        [format]: http://ipython.readthedocs.io/en/stable/api/generated/IPython.core.formatters.html#IPython.core.formatters.MarkdownFormatter\n",
    "        \"\"\"\n",
    "        from types import MethodType\n",
    "        def _repr_markdown_(module):\n",
    "            return \"`%s`\\n\\n---\\n%s\"%(repr(module), module.__doc__ or \"\"\"\"\"\")\n",
    "        module._repr_markdown_ = MethodType(_repr_markdown_, module)\n",
    "        return module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying:\n",
      "    m = from_file('aye.ipynb')\n",
      "Expecting nothing\n",
      "ok\n",
      "Trying:\n",
      "    mods = set(dir(__import__('sys').modules))\n",
      "Expecting nothing\n",
      "ok\n",
      "Trying:\n",
      "    assert m.__complete__ is True\n",
      "Expecting nothing\n",
      "ok\n",
      "Trying:\n",
      "    assert m.__name__\n",
      "Expecting nothing\n",
      "ok\n",
      "Trying:\n",
      "    assert len(set(dir(__import__('sys').modules)) - mods) is 0\n",
      "Expecting nothing\n",
      "ok\n",
      "31 items had no tests:\n",
      "    __main__\n",
      "    __main__.Import\n",
      "    __main__.Literate\n",
      "    __main__.Literate.source_to_lines\n",
      "    __main__.MD\n",
      "    __main__.MD.source_to_lines\n",
      "    __main__.Markdown\n",
      "    __main__.Markdown.render\n",
      "    __main__.NBDecoder\n",
      "    __main__.Notebook\n",
      "    __main__.Notebook.source_to_lines\n",
      "    __main__.Partial\n",
      "    __main__.Partial.exec_module\n",
      "    __main__.Partial.source_to_code\n",
      "    __main__.Partial.source_to_lines\n",
      "    __main__.Renderer\n",
      "    __main__.Renderer.__init__\n",
      "    __main__.Renderer.block_code\n",
      "    __main__.Transformer\n",
      "    __main__.Transformer.reset\n",
      "    __main__.ast\n",
      "    __main__.copy_module\n",
      "    __main__.f\n",
      "    __main__.free_expressions\n",
      "    __main__.lines_to_ast\n",
      "    __main__.new_decoder\n",
      "    __main__.parameterize\n",
      "    __main__.register_transforms\n",
      "    __main__.repr_markdown\n",
      "    __main__.update_hooks\n",
      "    __main__.vars_to_sig\n",
      "1 items passed all tests:\n",
      "   5 tests in __main__.from_file\n",
      "5 tests in 32 items.\n",
      "5 passed and 0 failed.\n",
      "Test passed.\n",
      "[NbConvertApp] Converting notebook aye.ipynb to script\r\n",
      "[NbConvertApp] Writing 15230 bytes to __init__.py\r\n",
      "\u001b[1m============================= test session starts ==============================\u001b[0m\r\n",
      "platform darwin -- Python 3.6.3, pytest-3.2.1, py-1.4.34, pluggy-0.4.0\r\n",
      "rootdir: /Users/tonyfast/eye, inifile:\r\n",
      "plugins: ipynb-1.1.0, hypothesis-3.44.6\r\n",
      "\u001b[1m\r",
      "collecting 0 items                                                              \u001b[0m\u001b[1m\r",
      "collecting 7 items                                                              \u001b[0m\u001b[1m\r",
      "collecting 9 items                                                              \u001b[0m\u001b[1m\r",
      "collecting 12 items                                                             \u001b[0m\u001b[1m\r",
      "collecting 14 items                                                             \u001b[0m\u001b[1m\r",
      "collecting 19 items                                                             \u001b[0m\u001b[1m\r",
      "collecting 21 items                                                             \u001b[0m\u001b[1m\r",
      "collected 21 items                                                              \u001b[0m\r\n",
      "\r\n",
      "tests/test_basics.ipynb .......\r\n",
      "tests/test_debug.ipynb ..\r\n",
      "tests/test_from_file.ipynb ...\r\n",
      "tests/test_md_import.ipynb ..\r\n",
      "tests/test_ordering.ipynb .....\r\n",
      "tests/test_parameterize.ipynb ..\r\n",
      "\r\n",
      "\u001b[32m\u001b[1m========================== 21 passed in 12.25 seconds ==========================\u001b[0m\r\n",
      "parsing __init__.py...\r\n",
      "\u001b]0;IPython: eye/aye\u0007wrote aye.html\r\n"
     ]
    }
   ],
   "source": [
    "    if 1 and __name__ ==  '__main__':\n",
    "        from IPython import get_ipython\n",
    "        __import__('doctest').testmod(verbose=2)\n",
    "        !jupyter nbconvert --to script --output __init__ aye.ipynb\n",
    "        !source activate p6 && py.test\n",
    "        !pyreverse -o png -p aye -A __init__.py\n",
    "        !ipython -m pydoc -- -w aye\n",
    "        !mv aye.html ../docs/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Permissive Markdown Source\n",
    "\n",
    "[Transform the full block][transform]\n",
    "\n",
    "[transform]: http://ipython.readthedocs.io/en/stable/config/inputtransforms.html#transforming-a-full-block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    from IPython.core.inputtransformer import InputTransformer\n",
    "\n",
    "    class Transformer(__import__('collections').UserList, InputTransformer):\n",
    "        push = __import__('collections').UserList.append        \n",
    "        def reset(Transformer): \n",
    "            source, Transformer.data = '\\n'.join(Transformer), []\n",
    "            return Markdown(Renderer()).render(source)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indenting Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    def register_transforms(ip=None):\n",
    "        from IPython import get_ipython\n",
    "        global _NATIVE_TRANSFORM\n",
    "        ip = ip or get_ipython()\n",
    "        _NATIVE_TRANSFORM = globals().get('_NATIVE_TRANSFORM', ip.input_transformer_manager)\n",
    "        ip.input_transformer_manager.logical_line_transforms = []\n",
    "        ip.input_transformer_manager.physical_line_transforms = []\n",
    "        ip.input_transformer_manager.python_line_transforms = [Transformer()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "    if __name__ == '__main__':\n",
    "        nb = from_file('aye.ipynb', capture=True)\n",
    "\n",
    "        f = parameterize(nb)\n",
    "        \n",
    "\n",
    "        m = f(x=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    from ipywidgets import interact\n",
    "\n",
    "    interact(f)\n",
    "\n",
    "    [publish_display_data(object.data) for object in nb.__output__.outputs];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from aye import update_hooks, Notebook\n",
    "update_hooks(Notebook)\n",
    "\n",
    "\n",
    "import mod_from_nb\n",
    "\n",
    "mod_from_nb.__complete__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p6",
   "language": "python",
   "name": "other-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
